Sigyn has multiple embedded boards to provide functionality by:
* Reading sensors
  * There are 8 time-of-flight sensors to provide obstacle distance monitoring at the four corners of the robot. Each corner has a pair of sensors pointed 90 degrees apart and mounted about 5 cmd above the base of the robot which itself is 7.5 cm above the floor. The VL53L0X sensors are intended to look for obstacles from a few millimeters out to about a meter and they can see objects that the other sensors cannot.
  * There will be 4 SONAR sensors mounted midway between the 4 corners of the robot. The will be mounted probably near 20 cm above the base of the robot. They can sense from a cm or two to about 2 meters from the robot and are better at sensing different kinds of objects and surfaces than the robot's LIDARs or the time-of-flight sensors.
  * There will be multiple temperature monitors. There is one mounted on each of the two motors that provide differential-drive for the robot. They are intended to provide a safety alert and cause an e-stop if the motors overheat.
  * There are monitors for voltage and current for each of:
    * The 36 volt, 30 amp-hour LIPO battery which drives the whole system.
    * The 24 volt DC-DC converter which supplies power to the two wheel motors as well as servos to drive the gripper assembly.
    * The 12 volt DC-DC converter which primarily supplies power the the Mini-ITX form factor PC  which has an AMD7900 processor to provide the main computing for the robot.
    * The 5 volt DC-DC converter which supplies the PC as well the embedded boards and several other peripherals.
    * The 3.3 volt DC-DC converter which supplies the PC and may supply a few other peripherals.
    * A pair of BNO055 IMUs to help with ROS2 navigation.
* Controlling peripherals
  * There is a RoboClaw 2x15 motor driver controlled by one embedded board. One embedded board receives cmd_vel commands from the ROS2/Jazzy system and converts those velocity requests into motor commands, then converts the wheel encoder values into odometry values. There is also logic to look for unsafe conditions such as runaway where the wheels are spinning out of control and motor over current where the robot has run into something and forcing the wheels to stop or turn slowly which will cause the motor windings to melt if not delt with quickly.
  * One embedded board is responsible for controlling the gripper's elevator and horizontal extender stepper motors.
  * One embedded board is responsible for controller a servo which opens and closes the robot's gripper for grasping objects.
  * A OAK-D camera provides objects recognition and scene segmentation as well as RGB stereo images and depth point clouds to help with ROS2 navigation.
  * A Raspberry Pi Camera 3 is fed into the same Raspberry PI 5 which controls the gripper's servo. The PI 5 has an AI hat. The camera is intended to help in grasping by providing object recognition to help position the gripper and recognize when an object has been grasped. The will probably be VL53L0X to help with distance detection for the gripper as well.

  The Teensy boards need to provided fast processing, which is why they are not implemented with, say, a Raspberry PI or something which runs a preemptive scheduler. To aid in easy of impelementation of all of the functions and performance monitoring, the Teensy boards have some common code they all use.

  * There is a Module class. Nearly every sensor or device that would benefit from the use of a setup() and loop() method derives from this class. Just by instantiating a singleton instance of a Monitor subclass, the subclass adds itself to the list of instantiated Modules. The main setup() and loop() methods for the Teensy call the Monitor's Setup() and Loop() methods and the Monitor class then loops over all the instantiated subclasses and calls their setup() and loop() methods. For the loop() calls, Monitor also wraps the call with code to capture the minimum, maximum and average execution times. Once per second, Monitor sends out a message summarizing the min/max/average loop execution time for all of the modules, allowing me, or an alert system, to see if any module is running out of spec. Currently there is no system checking to see if modules are running out of spec on the main PC which sees these messages. I'm going to want to add that functionality with a configuration yaml file that specifies the expected min/max/average times and can signal some sort of alert if some module suddently is misperforming.
  * There is an SD class which allows writing log data to the micro SD card on the Teensy. This allows writing a fair amount of low level data which can be later looked at if something goes wrong. Currently, the data does not include ROS time stamps. I want to add functionality that allows the PC system to periodically send the current ROS time to the teensy boards and have them pick it up for time stamp synchronization, also using internal clock to compute time offsets from the last synchronized time. This will allow me to read back the log files when I use the ros2bag system and I can synchronize the SD logs with the other ROS2 messages recorded to the ROS2 bag system.
  * There is a SerialManager class. This class is responsible for sending all of the messages of interest from the Module subclasses back to the connected PC system over the USB channel (via the Serial port) as well as receiving commands from the PC, decoding them, and making calls to the appropriate Module subclass. SerialManage also include code to request a directory listing from SD card and the ability to play back the log from a file on the SD card.

  Since Sigyn uses ROS2 to provide autonomous functionality, the Teensy boards must be both responsive to commands from the PC and provide relatively high rates of sensor data back to the PC in predictable intervals. It is important that sensor data has low latency as the robot is moving and needs to know what the state of the world is at any given time with some certainty. If, for instance, the wheel odometry was out of sync with what the PC sense of time was, the PC could end up driving the robot into an obstacle. Likewise, the Teensy is looking to verify that the robot is in a safe state, that the motor controller isn't overheating nor are the motors, that the motors aren't in a stall state and about to melt the windings by using too much current or that the motors aren't in a runaway condition because the wheel encoder connections are failing. 

  Note that I want to better use the RoboClaw. I want to specify voltage safety limits and current safety limits to the controller, which I don't do know. If there are other ways to better use the RoboClaw I want to discover them. Currently, the Teensy takes cmd_vel messages from the PC and computes the needed motor velocity for the pair of motors. It computes an acceleration and decelleration profile so that the motors won't get hit with huge current spikes. It expects to get regular motor commands from the PC so for each cmd_vel message, knowing that it expects to get, say, 20 cmd_vel messages a second, for the give motor velocity it computes how far it should move in the 1/20 of a second and tells the RoboClaw to move no further than that in it's commands. This is part of the safety system--if commands stop coming in regularly, it wants to motors to safely stop. If the motor handling code detects a safety violation, it sends an e-stop to the RoboClaw. Currently, the e-stop is reset when it sees a command to stop (velocity is zero) from the PC.

  So, the code for each kind of Module has to be "tricky" in that is must guarantee that any call to it's loop() method returns quickly. The sum of all loop() calls from the Module class itself over all of the submodules must try to be fast enough so that at least 80 loops per second happens. If this is missed for some configurable number of times in a row, a safety violation should be signaled. Currently, this isn't tested by the Teensy or the PC and I want to add that test.

  As an example, the VL53L0X code knows the if you attmept to read the distance from a sensor before it has time to make the calculation, the code will block until the data is ready, so the code schedules the reads to only happen after that time span. This has to be handled on a per device basis.

  Similarly, the SONAR senors must meet time demands for shaping the timing of the trigger signal and should only accept echo results in some time window. The echo signal is handled by a hardware interrupt so that the devices don't have to be polled. Currently, signals that come to late (that is, the detected surface is too far away) are not ignore, but the code should deal with that. This especially could happen if the sonar ping from once sensor ends up bouncing around the house and is picked up by another sensor. I want to fix that for the SONAR code.

  So I want you to do a deep look at the code in the Teensy directory and analyze it's architecture against this description and evaluate it. If you think it should be improved, make suggestions and I will direct you to implement suggestions one at a time if I agree. Feel free to loop at the web to find other knowledge about what people have done if you think that would help. Ask questions if needed.